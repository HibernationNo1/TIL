# 데이터 셋

##### 종류

1. MNIST 데이터 셋
2. CIFAR-10 데이터 셋
3. kaggle 데이터 셋

### 1. MNIST 데이터 셋

머신러닝 모델을 학습시키기 위해서는 많은 데이터가 필요하고, 데이터를 학습에 적합한 형태로 정제하는 것은 많은 시간과 노력이 필요하기 때문에 많은 연구자가 학습하기 쉬운 형태로 데이터들을 미리 정제해서 웹상에 공개해놓은 것.

그 중에서도 MNIST 데이터 셋은 머신러닝을 공부하는 사람들이 가장 먼저 접하게 되는 데이터셋이다.

**특징**

- 28*28 형태의 데이터가 공유되고 있다.

- 컬러값이 없기 때문에 컬러채널을 없다.

- train데이터 6만개, test데이터 1만개가 존재한다.
- MNIST 데이터는 기본적으로 int타입의 0~255 Pixel Intensity(화소 강도)를 가지고 있다.



#### **코드구현**

**MNIST 데이터를 받아와서 One-hot Encoding형태로 변경해주는 코드**

tensorflow 활용

**순서**

1. MNIST 데이터 다운로드 

2. 데이터 flatteing

   > flattening: 데이터의 차원을 변경하는 것

3. one-hot encoding을 적용



**세부 순서**

##### 1. MNIST 데이터 다운로드

tf.keras.datasets 의 mnist 모듈에서 제공하는load_data()라는 함수 호출

```python
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
```

> - load_data()
>
>   6만개의 mnist 데이터를 반환해준다.
>
>   - [60000, 28, 28] 형태의 차원을 가진 형태가 x_train 데이터의 리턴값으로 넘어간다.
>   - interger Encoding으로 되어있는 60000개의 정답 mnist 데이터가  y_train으로 리턴된다.
>   - [10000, 28, 28] 형태의 차원을 가진 형태가 x_test 데이터의 리턴값으로 넘어간다.
>
>   - interger Encoding으로 되어있는 10000개의 정답 mnist 데이터가  y_test로 리턴된다.
>
>   데이터 타입은 numpy 타입으로 반환된다.

##### 2. 데이터 타입 변경

load_data()에 의해 반환된 이미지 데이터는 int형이기 때문에 float32 데이터로 변경

```python
x_train, x_test = x_train.astype('float32'), x_test.astype('float32')
```

> numpy 모듈에서 제공하는 astype()메서드 사용
>
> astype(): numpy 모듈에서 제공하는 데이터타입 변경 메서드 

##### 3. flattening

load_data()에 의해 반환된 이미지 데이터는 28*28 형태의 2차원 이미지기 때문에 784개의 1차원 데이터로 flattening 한다.

```python
x_train, x_test = x_train.reshape([-1, 784]), x_test.reshape([-1, 784])
```

> 2차원의 mnist 데이터는 softmax에 사용할 수 없기 때문에 1차원의 데이터로 변경하는 과정
>
> reshape(): numpy 모듈에서 제공하는 데이터 차원 변경 메서드
>
> reshape([-1, 784]): 첫 번째 인자로**-1**을 넣으면 reshape함수가 알아서 몇 개(6만개) 데이터의 차원을 변경해야 하는지 인지한다

##### 4. Normalize(정상화)

2번에서 int 타입이 float32타입으로 변경됐기 때문에 Pixel Intensity 값을 0~255에서 0~1로 변경한다.

```python
x_train, x_test = x_train / 255., x_test / 255.
```

##### 5. one-hot encoding 적용

정답 데이터가 interger Encoding으로 되어있기 때문에 해당 데이터 각각에 one-hot encoding을 적용해서 [[60000] * 10]으로 변환한다.

```python
y_train, y_tset = tf.one_hot(y_train, depth=10), tf.one_hot(y_test, depth=10)
```

> tf.one_hot API를 사용해서 6만 * depth 의 2차원 데이터 생성



##### - 전체 코드 -

```python
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() 
x_train, x_test = x_train.astype('float32'), x_test.astype('float32')
x_train, x_test = x_train.reshape([-1, 784]), x_test.reshape([-1, 784])
x_train, x_test = x_train / 255., x_test / 255.
y_train, y_tset = tf.one_hot(y_train, depth=10), tf.one_hot(y_test, depth=10)
```

---



### 2. CIFAR-10 데이터 셋

10개의 클래스, 50000개의 트레이닝 이미지, 10000개의 트레이닝 이미지로 구성되어 있다.

이미지 크기는 32 * 33 *3 픽셀이고 Color Image임

MNIST 데이터보다 차원이 더욱 높은 이미지 데이터임



#### **코드 구현**

**CIFAR-10 데이터를 받아와서 One-hot Encoding형태로 변경해주는 코드**

```python
# CIFAR-10 데이터를 다운로드하고 데이터를 불러옵니다.
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()
# 이미지들을 float32 데이터 타입으로 변경합니다.
x_train, x_test = x_train.astype('float32'), x_test.astype('float32')
# [0, 255] 사이의 값을 [0, 1]사이의 값으로 Normalize합니다.
x_train, x_test = x_train / 255., x_test / 255.
# scalar 형태의 레이블(0~9)을 One-hot Encoding 형태로 변환합니다.
y_train_one_hot = tf.squeeze(tf.one_hot(y_train, 10), axis=1)
y_test_one_hot = tf.squeeze(tf.one_hot(y_test, 10), axis=1)
```

> `squeeze`: 1의 요소를 갖는 차원을 삭제해주는 API (더미 Dimension을 삭제)
>
> 불필요한 차원 요소값을 삭제

---



### 3. kaggle 데이터 셋

kaggle이란?  datasets을 공유하고 다루는 서비스

- [kaggle 웹 페이지](https://www.kaggle.com/)

kaggle API를 사용하면 datasets, kernels 등 을 다운받아서 쓰거나 여러 기능을 사용할 수 있다.

- [kaggle API git hub]([GitHub - Kaggle/kaggle-api: Official Kaggle API](https://github.com/Kaggle/kaggle-api))

##### kaggle API 사용법

Kaggle API를 사용하려면 kaggle 웹 페이지 로그인 후 계정 설정에서 Create New API Token을 다운 받아야 한다. (나만의 key를 받을 수 있다. 다운받은 json파일을 어디에 위치해야 하는지 해당 페이지 상단에 초록색 박스로 표시되어 있음) 

1. Colab에서 사용

json파일에서 유저이름과 비밀번호만 받아내면 됨

```python
import os
os.environ ['KAGGLE_USERNAME] = 'TaeUk Noh'
os.environ ['KAGGLE_KEY'] = 'xxxxxxxxxxxxxx'
```

2. **PC에서 사용**

   1. pip를 통해 Kaggle API를 다운

      ```
      $ pip install kaggle
      ```

   2. Create New API Token다운받아서 키 얻음

   3. 다운받은 파일을 위치 변경

      - 윈도우: *C:\Users\<Windows-username>\.kaggle\kaggle.json* 
      - 리눅스:  ~/.kaggle/kaggle.json

   4. 캐글API 사용자 key를 세팅

      ```
      $ export KAGGLE_USERNAME=taeuknoh
      $ export KAGGLE_KEY=xxxxxxxxx
      ```

   5. 확인

      ```
      $ export -p
      ```

   자세한 내용은 [여기](https://github.com/Kaggle/kaggle-api)



##### data 가져오는 법

웹페이지에서 로그인 후 data 페이지 -> 원하는 data -> data 탭 오른쪽 `...` 부분-> copy API

```
//예시
$ kaggle datasets download -d shivamb/netflix-shows //붙여넣기
$ unzip '*.zip'  // 압축 해제
```

이후 코드에서 pandas 라이브러리를 활용해 csv파일을 읽어들인다.



