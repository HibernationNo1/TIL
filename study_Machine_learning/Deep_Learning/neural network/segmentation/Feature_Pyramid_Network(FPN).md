# Feature Pyramid Network(FPN)

FPN은 backbone network의 각각의 layer를 통해 얻어진 feature map을 사용해서 object detection을 수행한다.



- Region Proposal Network와 Feature Pyramid Network의 차이점

  RPN은 backbone network의 output인 feature map을 받아 다양한 size의 anchor를 대응시켜 object detection을 수행하도록 한다.

  > backbone network의 last layer의 output만 사용한다.

  FPN은 backbone network의 내부 layer 각각의 output인 feature map에 anchor를 대응시켜 object detection을 수행하도록 한다.

![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FDFL4S%2FbtqEeX5IAp0%2FCbvO9zsvHU9Z6fNcrFkf8K%2Fimg.jpg)



### Process

#### Bottom-up pathway

backbone network의 각각의 layer로부터 feature map (C1, C2, C3, C4, C5)를 계산한다.

> input image size : 1024×1024
>
> conv1(str = 2)의 output size   // conv1은 큰 memory를 차지하기 때문에 ptramid에 포함시키지 않는다.

- stage-2의 output shape(C2) = 64×64×256
- stage-3의 output shape(C3) = 32×32×512
- stage-4의 output shape(C4) = 16×16×1024
- stage-5의 output shape(C5) = 8×8×2048



#### Top-down pathway

Bottom-up과정에서 계산한 feature map (C2, C3, C4, C5)을 통해 feature map (M2, M3, M4, M5)을 계산한다.

- M5계산 방법

  feature map C5에 1×1 conv1 layer을 통해 채널 수를 256개로 맞춰준다.

  > 채널 수를 256개로 맞추는 이유
  >
  > M5, 4, 3은 결국 M2의 계산에 활용되는데 M2의 channel이 256이기 때문에 통일시켜준다. 

  output shape(M5) = 8×8×256

- M4계산 방법

  1. 계산된 M5의 size을 2배로 upsampling한다.

  2. feature map C4에 1×1 conv1 layer을 통해 채널 수를 256개로 맞춰준다.
  3. 1번과 2번 과정으로 계산된 각 feature map을 element-wise addition 연산을 수행한다.

  M3, M2의 계산 과정도 동일하다.

  output shape(M4) = 16×16×256

  output shape(M3) = 32×32×256

  output shape(M2) = 64×64×256

  

M4는 M5의 정보를, M2는 M3, 4, 5의 정보를 담고 있기 때문에 한 개의 feature map에 대해서 여러 scale의 anchor를 생성할 필요가 없게 된다.



#### output feature map

feature map (M2, M3, M4, M5)로부터 feature map (P2, P3, P4, P5)을 계산한다.

- 계산 

  M5에 3×3 conv연산을 수행하고 channel은 128로 통일한다.

  > F2~F5는 upsampling과 이전 feature map의 addition과정을 통해 feature data가 학습에 맞지 않게 망가졌을 수 있기 때문이다.
  
  output shape(P2) = 64×64×128
  
  output shape(P3) = 32×32×128
  
  output shape(P4) = 16×16×128
  
  output shape(P5) = 8×8×128



![](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb2vbLx%2FbtraGFFzB47%2F7DklJHSXGkNfx0IEZb8lOk%2Fimg.png)



### code

```python
from tensorflow.keras.layers import Conv2D, Add, UpSampling2D, MaxPooling2D

TRAIN_BN = False 		# Train or freeze layers
BACKBONE = "resnet101"

# Size of the top-down layers used to build the feature pyramid
TOP_DOWN_PYRAMID_SIZE  = 256

TOP_DOWN_LAST_FILTER = 128 		# not config

def fpn_graph(input_image):
    # Build the shared convolutional layers.
    # Bottom-up Layers
    _, C2, C3, C4, C5 = resnet_graph(input_image, BACKBONE,
                                             stage5=True, train_bn=TRAIN_BN)
    
    # Top-down Layers
    # TODO: add assert to varify feature map sizes match what's in config
    M5 = Conv2D(TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c5p5')(C5)
    
    M4 = Add(name="fpn_p4add")([
             UpSampling2D(size=(2, 2), name="fpn_p5upsampled")(M5),
             Conv2D(TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c4p4')(C4)])
    
    M3 = Add(name="fpn_p3add")([
             UpSampling2D(size=(2, 2), name="fpn_p4upsampled")(M4),
             Conv2D(TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c3p3')(C3)])
    
    M2 = Add(name="fpn_p2add")([
             UpSampling2D(size=(2, 2), name="fpn_p3upsampled")(M3),
             Conv2D(TOP_DOWN_PYRAMID_SIZE, (1, 1), name='fpn_c2p2')(C2)])
    
    # Attach 3x3 conv to all P layers to get the final feature maps.
    P2 = Conv2D(TOP_DOWN_LAST_FILTER, (3, 3), padding="SAME", name="fpn_p2")(M2)
    P3 = Conv2D(TOP_DOWN_LAST_FILTER, (3, 3), padding="SAME", name="fpn_p3")(M3)
    P4 = Conv2D(TOP_DOWN_LAST_FILTER, (3, 3), padding="SAME", name="fpn_p4")(M4)
    P5 = Conv2D(TOP_DOWN_LAST_FILTER, (3, 3), padding="SAME", name="fpn_p5")(M5)
    
    # P6 is used for the 5th anchor scale in RPN. Generated by
    # subsampling from P5 with stride of 2.
    P6 = MaxPooling2D(pool_size=(1, 1), strides=2, name="fpn_p6")(P5)
    
    # Note that P6 is used in RPN, but not in the classifier heads.
    rpn_feature_maps = [P2, P3, P4, P5, P6]
    mrcnn_feature_maps = [P2, P3, P4, P5]
```
