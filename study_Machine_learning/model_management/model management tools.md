# Model managiment tools

| **용어**           | **예시**                   | **설명**                                                   |
| ------------------ | -------------------------- | ---------------------------------------------------------- |
| **모델 서빙 도구** | Triton, TensorFlow Serving | 모델을 실제 환경에 배포하고, 추론 서비스를 제공            |
| **추론 엔진**      | TensorRT, ONNX Runtime     | 학습된 모델을 최적화하고 빠르게 추론할 수 있도록 지원      |
| **모델 포맷**      | ONNX                       | 다양한 프레임워크 간 모델 호환성을 위한 표준화된 포맷 제공 |

- 모델 서빙/배포 도구 (Model Serving Tool):

  학습된 머신러닝 모델을 실제 환경에서 배포하고 서비스하는 데 사용된다.

  클라이언트의 요청에 따라 모델 추론을 수행하고 결과를 반환하는 역할을 한다.

  - 예: Triton, TensorFlow Serving

- 추론 엔진/프레임워크 (Inference Engine/Framework):

  학습된 모델을 최적화하고 빠르게 추론할 수 있도록 설계된 최적화 library

  주로 고성능 추론을 위해 모델을 가속하고 리소스를 효율적으로 사용하는 데 집중한다.

  - 예: TensorRT, ONNX Runtime

- 모델 포맷/표준화 포맷 (Model Format/Standardization):

  딥러닝 프레임워크 간의 호환성을 위해 표준화된 모델 파일 형식. 

  다양한 프레임워크의 모델을 하나의 표준 포맷으로 변환하여 다양한 환경에서 동일한 모델을 사용할 수 있게 해준다.

  - 예: ONNX



