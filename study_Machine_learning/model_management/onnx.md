## ONNX

**ONNX (Open Neural Network Exchange)**는 다양한 딥 러닝 프레임워크 간에 모델을 상호 운용 가능하게 만들어주는 open source 형식이다.

- **ONNX의 주요 특징**

  - 범용성

    ONNX는 여러 프레임워크에서 지원하는 모델을 표현할 수 있도록 표준화된 모델 파일 형식을 제공한다. 

    ONNX 형식의 모델을 사용하면 한 프레임워크에서 훈련한 모델을 다른 프레임워크에서 쉽게 로드하여 사용할 수 있다.

    예를 들어, PyTorch에서 훈련한 모델을 ONNX로 변환하면 그 모델을 ONNX 파일로 **TensorFlow, MXNet, 또는 ONNX Runtime**과 같은 다른 플랫폼에서 직접 로드하여 추론에 사용할 수 있다.

  - 고속 추론 지원

    ONNX는 고속 추론을 위해 **ONNX Runtime**과 함께 사용할 수 있다. 

    특히, CPU 기반에서 ONNX는 최적화된 속도로 추론을 실행할 수 있으며, 모바일 및 임베디드 장치에서도 효율적으로 실행된다.

    - **ONNX Runtime**

      ONNX(Open Neural Network Exchange) 포맷으로 변환된 모델을 효율적으로 실행하기 위해 Microsoft에서 개발한 고성능 추론 엔진

  - 다양한 하드웨어 가속기 지원

    ONNX는 GPU뿐 아니라 CPU, FPGA, 모바일 장치 등 다양한 하드웨어 가속기에서 작동하도록 최적화되어 있다. 

    이를 통해 더 빠른 추론을 지원하며, 특히 배포 시 비용을 절감하는 데 도움이 된다.

  - 생산 환경에서의 유연성

    ONNX를 사용하면 모델을 다양한 환경에 배포할 수 있다. 

    예를 들어, 클라우드, 모바일 장치, 엣지 컴퓨팅 환경 등 여러 환경에서 ONNX 형식을 활용하여 모델을 운영할 수 있다.

- **ONNX 파일 구조**

  ONNX 파일은 모델의 연산 그래프가 담겨져 있어 **계층적 연산자**와 **네트워크 레이어 구조**로 구성되어 있다.

  이를 **프로토콜 버퍼 형식**을 사용하여 직렬화 하여 `.onnx` 확장자를 가진 프로토콜 버퍼 형식의 단일 파일로 저장한 것이다.

  이 파일은 모델의 연산 그래프(계층) 및 가중치, 하이퍼파라미터 등의 메타데이터를 포함하고 있어 모델의 이동성(프레임워크 변환)을 보장한다.

  



