# Back Propagation

인공 신경망의 학습은 오차를 최소화하는 가중치를 찾는 목적으로 순전파와 역전파를 반복하는 것을 말한다.

간단한 문제들 같은 경우 역전파 알고리즘을 사용하지 않고 Normal Equation이나 Cost Function의 해를 바로 구하는 방식으로 풀어낼 수 있지만 복잡하고 어려운 문제들은 역전파 알고리즘을 사용하는 것이 더 효율적이다.

- 순전파(foward Propagation)

  input에서 output으로 Weight를 업데이트 하면서 활성화 함수를 통해 결과값을 가져오는 것이다.하지만 우리가 임의로 한 번 순전파 했다고 출력 값이 정확하지는 않을 것이다. 우리가 임의로 설정한 가중치 값이 input에 의해서 한 번 업데이트 되긴 했지만 많은 문제가 있을 수 있다.

- 역전파(Back Propagation)

  결과 값을 통해서 다시 역으로 input 방향으로 오차를 다시 보내며 Weight를 재업데이트 하는 것이다. 물론 결과에 영향을 많이 미친 노드(뉴런)에 더 많은 오차를 돌려줄 것이다.

  ![](https://i.stack.imgur.com/H1KsG.png)

##### 역전파를 이용한 Weight 업데이트 절차

1. 역전파 1단계

   output으로부터 바로 이전의 은닉층과 출력층 사이의 Weight 업데이트

2. 역전파 2단계

   output으로부터 첫 번째 층 그 다음층의 모든 Weight를 역으로 거슬러가며 업데이트

3. 업데이트 된 가중치에 대해서 다시 한 번 순전파를 진행하여 최초 순전파의 오차보다 감소된 오차값을 계산할 수 있다.