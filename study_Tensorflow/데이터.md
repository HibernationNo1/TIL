# 데이터

## 트레이닝 데이터, 검증용 데이터, 테스트 데이터

머신러닝 모델은 크게 트레이닝 과정과 테스트 과정으로 나뉜다.  트레이닝과 테스트를 수행하기 위해서 가지고 있는 데이터 중 일부는 트레이닝 데이터, 일부는 테스트 데이터로 나눈다.

전체 데이터는 트레이닝 데이터, 검증용 데이터, 테스트 데이터로 나눈다.

검증용 데이터는 트레이닝 과정에서 학습에 사용하지는 않지만 중간중간 테스트하는데 사용해서 학습하고 있는 모델이 오버피팅에 빠지지 않았는지 체크하는데 사용된다.

**검증용 데이터가 필요한 이유**

> 처음에는 트레이닝 에러와 검증 에러가 모두 작아지지만 일정 횟수 이상 반복할 경우 트레이닝 에러는 작아지지만 검증 에러는 커지는 **overfitting**(과적합)에 빠지게 된다. (모델이 범용적으로 좋은 방향으로 개선되는것이 아닌, 트레이닝만을 위한 방향으로 개선되는 것)
>
> 따라서 트레이닝 에러는 작아지지만 검증 에러는 커지는 지점에서 업데이트를 중지하면 최적의 파라미터를 얻을 수 있다.
>
> 이를 위해 검증용 데이터를 사용하는 것.
>
> - 오버피팅: 학습 과정에서 머신러닝 알고리즘의 파라미터가 트레이닝 데이터에 과도하게 최적화되어 트레이닝 데이터에 대해서는 잘 동작하지만 새로운 데이터인 테스트 데이터에 대해서는 잘 동작하지 못하는 현상.
> - 언더피팅(underfitting): 오버피팅의 반대 상황으로 모델의 표현력이 부족해서 트레이닝 데이터도 제대로 예측하지 못하는 현상
>
> 딥러닝의 경우 모델의 표현력이 강력하기 때문에 오버피팅에 빠지기 쉽기 때문에 오버피팅 문제를 완화하기 위해서 드롭아웃(dropout)과 같은 다양한 Regularization 기법을 사용한다.
>
> - Regularization 기법: 오버피팅을 방지하는 기법들을 총칭하는 단어



## MNIST 데이터 셋

머신러닝 모델을 학습시키기 위해서는 많은 데이터가 필요하고, 데이터를 학습에 적합한 형태로 정제하는 것은 많은 시간과 노력이 필요하기 때문에 많은 연구자가 학습하기 쉬운 형태로 데이터들을 미리 정제해서 웹상에 공개해놓은 것.

그 중에서도 MNIST 데이터 셋은 머신러닝을 공부하는 사람들이 가장 먼저 접하게 되는 데이터셋이다.

**특징**

- 28*28 형태의 데이터가 공유되고 있다.

- 컬러값이 없기 때문에 컬러채널을 없다.

- train데이터 6만개, test데이터 1만개가 존재한다.
- MNIST 데이터는 기본적으로 int타입의 0~255 Pixel Intensity(화소 강도)를 가지고 있다.



## One-hot Encoding

One-hot Encoding은 범주형 값을 이진화된 값로 바꿔서 표현하는 것을 의미한다. 

- ex)

  - interger Encoding(범주형 값)

    개, 고양이, 말 이라는 3개의 데이터가 있을 때 이를 ['개' = 1, '고양이' = 2, '말' = 3 ] 이라고 단순하게 interger Encoding으로 변환하여 표현하는 것.

    > 이러한 Encoding의 문제점은 머신러닝 알고리즘이 정수 값으로부터 잘못된 경향성을 학습하게 될 수도 있다. ['개' 와 '말' 의 평균은 '고양이' 이다.] 라는 잘못된 학습이 이루어질 수 있기 때문이다.

  - One-hot Encoding을 

    범주형 데이터를 '개' = [1 0 0], '고양이' = [0 1 0], '말' = [0 0 1] 형태로 해당 레이블을 나타내는 인덱스만 1의 값을 가지고 나머지 부분은 0의 값을 가진 Binary Value로 표현한 것



### **MNIST 데이터를 받아와서 One-hot Encoding형태로 변경해주는 코드**

**순서**

1. MNIST 데이터 다운로드 

2. 데이터 flatteing

   > flattening: 데이터의 차원을 변경하는 것

3. one-hot encoding을 적용



**세부 순서**

#### 1. MNIST 데이터 다운로드

tf.keras.datasets 의 mnist 모듈에서 제공하는load_data()라는 함수 호출

```python
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()
```

> - load_data()
>
>   6만개의 mnist 데이터를 반환해준다.
>
>   - [60000, 28, 28] 형태의 차원을 가진 형태가 x_train 데이터의 리턴값으로 넘어간다.
>   - interger Encoding으로 되어있는 60000개의 정답 mnist 데이터가  y_train으로 리턴된다.
>   - [10000, 28, 28] 형태의 차원을 가진 형태가 x_test 데이터의 리턴값으로 넘어간다.
>
>   - interger Encoding으로 되어있는 10000개의 정답 mnist 데이터가  y_test로 리턴된다.
>
>   데이터 타입은 numpy 타입으로 반환된다.

#### 2. 데이터 타입 변경

load_data()에 의해 반환된 이미지 데이터는 int형이기 때문에 float32 데이터로 변경

```python
x_train, x_test = x_train.astype('float32'), x_test.astype('float32')
```

> numpy 모듈에서 제공하는 astype()메서드 사용
>
> astype(): numpy 모듈에서 제공하는 데이터타입 변경 메서드 

#### 3. flattening

load_data()에 의해 반환된 이미지 데이터는 28*28 형태의 2차원 이미지기 때문에 784개의 1차원 데이터로 flattening 한다.

```python
x_train, x_test = x_train.reshape([-1, 784]), x_test.reshape([-1, 784])
```

> 2차원의 mnist 데이터는 softmax에 사용할 수 없기 때문에 1차원의 데이터로 변경하는 과정
>
> reshape(): numpy 모듈에서 제공하는 데이터 차원 변경 메서드
>
> reshape([-1, 784]): 첫 번째 인자로**-1**을 넣으면 reshape함수가 알아서 몇 개(6만개) 데이터의 차원을 변경해야 하는지 인지한다

#### 4. Normalize(정상화)

2번에서 int 타입이 float32타입으로 변경됐기 때문에 Pixel Intensity 값을 0~255에서 0~1로 변경한다.

```python
x_train, x_test = x_train / 255., x_test / 255.
```

#### 5. one-hot encoding 적용

정답 데이터가 interger Encoding으로 되어있기 때문에 해당 데이터 각각에 one-hot encoding을 적용해서 [[60000] * 10]으로 변환한다.

```python
y_train, y_tset = tf.one_hot(y_train, depth=10), tf.one_hot(y_test, depth=10)
```

> tf.one_hot API를 사용해서 6만 * depth 의 2차원 데이터 생성



#### - 전체 코드 -

```python
(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data() 
x_train, x_test = x_train.astype('float32'), x_test.astype('float32')
x_train, x_test = x_train.reshape([-1, 784]), x_test.reshape([-1, 784])
x_train, x_test = x_train / 255., x_test / 255.
y_train, y_tset = tf.one_hot(y_train, depth=10), tf.one_hot(y_test, depth=10)
```

