# 영상 처리



### 연산 시간 측정

computer vision은 대용량 데이터를 다루고, 일련의 과정을 통해 최종 결과를 얻으므로 매 단계에서 연산 시간을 측정하여 관리할 필요가 있다. 어떠한 알고리즘을 설계했을 때, 각각의 과정에서 연산 시간을 측정해서 그 시간을 줄이는 방향으로 노력하는 것이 매우 중요하다.

OpenCV에서는 TickMeter class를 이용해서 연산 시간을 측정할 수 있다.

#### cv2.TickMeter()

```python
tm = cv2.TickMeter()
```

`tm` : class instance



method

- `tm.start()` : 시간 측정 시작
- `tm.stop()` : 시간 측정 끝 
- `tm.reset()` : 시간 측정 초기화
- `tm.getTimeSec()` : 측정 시간을 초 단위로 반환
- `tm.getTimeMilli()` : 측정 시간을 milli 초 단위로 반환
- `tm.getTimeMicro()` : 측정 시간을 micro 초 단위로 반환



**예시**

```python
import sys
import numpy as np
import cv2

img = cv2.imread('hongkong.jpg')

if img is None:
    print('Image load failed!')
    sys.exit()
    
tm = cv2.TickMeter()
tm.start()	# 연산시간 측정 시작

edge = cv2.Canny(img, 50, 100) # edge 검출 함수 (그냥 예시로 가져온 것)
	
tm.stop()	# 연산시간 측정 끝
ms = tm.getTimeMilli()	# 측정된 시간을 milli sec으로 반환
print(f'Elapsed time : {ms}ms')
```

연산 시간이 너무 많이 걸린다면 어떠한 이유로 시간이 많이 소요됐는지를 찾아 해결하고자 하는 자세를 가져야 한다.



### 화소 처리

입력 image의 특정 좌표 pixel 값을 변경해서 출력 image의 해당 좌표 pixel 값으로 설정하는 연산
$$
dst(x, y) = f(src(x, y)) \\
f : transfer\ function
$$

> dst : 출력 image
>
> src : 입력 image

![](https://cdn.greenblog.co.kr/wp-content/uploads/2019/05/%EB%A0%88%EC%9D%B4%EC%96%B4-%EB%B3%B5%EC%82%AC-1024x521.jpg)

x축 : src, y축 : dst



#### 밝기 조절(cv2.add)

$$
dst(x, y) = saturate(src(x, y) + n)
$$

n만큼 밝아진 image가 출력된다.

**saturate** : n만큼의 수직 이동으로 인해 bottom 또는 top에 값이 완전히 밀착해버릴때 수행되는 연산을  saturate라고 한다.

![](https://blog.kakaocdn.net/dn/PvKl6/btqJDXzn63s/YdaJQTNQv8IerfwUjlDhA0/img.png)

```python
dst = cv2.add(src1, src2, dst = None, mask = None, dtype = None)
```

> `src1` : 첫 번째 입력 image
>
> `src1` : 두 번째 입력 image. 위 식에서 더해지는 n을 의미한다. 	
>
> 만약 n이 아닌, 다른 src를 입력하게 되면 말 그대로 두 image가 겹쳐진 모습으로 보여진다.
>
> `dst` : 출력 image
>
> `mask` : mask image
>
> `dtype` : dst의 type. 여기선 numpy의 dtype이 아닌, OpenCV의 dtype을 넣어줘야 하기 때문에 `cv2.CV_8U` 를 넣어줘야 한다.



**예시**

gray scale에선

```python
dst = cv2.add(src, 100)  # 100만큼 밝기 증가
```

> src는 ndarray이기 때문에 broadcasting을 이용하면 아래처럼 표현할 수 있다.
>
> ```python
> dst = src + 100
> ```
>
> 하지만 이는 saturate 연산이 이루어지지 않기 때문에 255보다 큰 값은 0으로 인식해버린다.

color scale에선 

```python
dst = cv2.add(src, (100, 100, 100, 0))  # 100만큼 밝기 증가
```



**그 외에도 다양한 밝기 조절 수식** 

- 가중치 합
  $$
  dst(x, y) = saturate(\alpha * src1(x, y) + \beta * src2(x, y))
  $$
  보통 alpha + beta = 1 이 되도록 설정 (두 입력 image의 mean 밝기를 유지하기 위해)

  ```python
  dst = cv2.addweighted(src1, alpha, src2, beta, gamma, dst = None, mask = None, dtype = None)
  ```

  > `gamma` : dst에 추가적으로 더할 값 (+n)

- 평균 연산
  $$
  dst(x, y) = \frac{1}{2}(src1(x, y) + src2(x, y))
  $$
  alpha = beta = 0.5

- 뺄셈 연산
  $$
  dst(x, y) = saturate(src1(x, y) - src2(x, y))
  $$

  ```python
  dst = cv2.subtract(src1, src2, dst = None, mask = None, dtype = None)
  ```

- 차이 연산

  두 형상의 같은 위치에 존재하는 픽셀 값에 대해서 뺄셈 연산 후 절대값을 씌운다.

  (틀린그림 찾기에서 틀린그림만 찾아내는데 사용될 수 있음)
  $$
  dst(x, y) = |src1(x, y) - src2(x, y)|
  $$

  ```python
  dst = cv2.absdiff(src1, src2, dst = None)
  ```

  

#### 논리 연산

두 연산의 각 pixel값을 이진수로 표현하고, 이에 대하여 비트 단위 AND, OR, XOR, NOT 연산을 수행

```python
dst = cv2.bitwise_and(src1, src2, dst = None, mask = None)
dst = cv2.bitwise_or(src1, src2, dst = None, mask = None)
dst = cv2.bitwise_xor(src1, src2, dst = None, mask = None)
dst = cv2.bitwise_not(src1, dst = None, mask = None)
```





### color

color image는 3 dim의 ndarray로 표현된다. `img.shape = (h, w, 3)`

OpenCV에서는 RGB순이 아닌, BGR순이다.

- 불러오기

  ```python
  img = cv2.imread('filename', cv2.IMREAD_COLOR)
  ```

- 생성

  ```python
  img = np.zeros((480, 640, 3), np.uint8)
  ```

- gary scale에서 color scale로 변경

  ```python
  img = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)
  ```

  

#### cv2.split()

color image의 세 채널을 각각 분리하는 함수

```python
dst = cv2.split(img)
```

`img` : color image

`dst` : 각각의 원소에 B, G, R 의 값을 가진 list



#### cv2.merge()

여러 채널을 결합하는 함수 (흑백 3개를 하나의 color로)

```python
dst = cv2.merge(mv, dst = None)
```

`mv` : 입력 image list (개의 원소를 가진 1 dimension)



#### cv2.cvtColor()

color image를 다른 scale의 image로 변환

```python
dst = cv2.cvtColor(src, code, dst = None, dstCn = None)
```

`code` 변환하고자 하는 scale의 코드

![](https://github.com/HibernationNo1/TIL/blob/master/image/c7.jpg?raw=true)

> 그 외 코드는 [OpenCV 문서 페이지](https://docs.opencv.org/master/) 참고

`dstCn` : 결과 영상의 채널 수. 0 이면 자동 결정

- RGB색상을 gra scale로 변환

  장점: 데이터 저장 용량 감소, 데이터 처리 속도 향상

  단점: 색상 정보 손실

