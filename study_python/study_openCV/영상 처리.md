# 영상 처리



### 연산 시간 측정

computer vision은 대용량 데이터를 다루고, 일련의 과정을 통해 최종 결과를 얻으므로 매 단계에서 연산 시간을 측정하여 관리할 필요가 있다. 어떠한 알고리즘을 설계했을 때, 각각의 과정에서 연산 시간을 측정해서 그 시간을 줄이는 방향으로 노력하는 것이 매우 중요하다.

OpenCV에서는 TickMeter class를 이용해서 연산 시간을 측정할 수 있다.

#### cv2.TickMeter()

```python
tm = cv2.TickMeter()
```

`tm` : class instance



method

- `tm.start()` : 시간 측정 시작
- `tm.stop()` : 시간 측정 끝 
- `tm.reset()` : 시간 측정 초기화
- `tm.getTimeSec()` : 측정 시간을 초 단위로 반환
- `tm.getTimeMilli()` : 측정 시간을 milli 초 단위로 반환
- `tm.getTimeMicro()` : 측정 시간을 micro 초 단위로 반환



**예시**

```python
import sys
import numpy as np
import cv2

img = cv2.imread('hongkong.jpg')

if img is None:
    print('Image load failed!')
    sys.exit()
    
tm = cv2.TickMeter()
tm.start()	# 연산시간 측정 시작

edge = cv2.Canny(img, 50, 100) # edge 검출 함수 (그냥 예시로 가져온 것)
	
tm.stop()	# 연산시간 측정 끝
ms = tm.getTimeMilli()	# 측정된 시간을 milli sec으로 반환
print(f'Elapsed time : {ms}ms')
```

연산 시간이 너무 많이 걸린다면 어떠한 이유로 시간이 많이 소요됐는지를 찾아 해결하고자 하는 자세를 가져야 한다.



### pixel operation

#### cv2.resize

```python
dst = cv2.resize(str, (width, height, channel), interpolation)
```



**interpolation**

- size를 늘릴때

  - `cv2.INTER_LINEAR` : Bilinear Interpolation

    이접한 4개의 pixel의 pixel value와 거리에 따른 weight의 곱을 사용하여 결정하는 보간법

  - `cv2.INTER_CUBIC` : bicubic Interpolation

    인접한 16개의 pixel에 대해 Bilinear Interpolation과 같은 동작을 수행하여 계산

  - `cv2.INTER_LANCZOS4` : Lanczos Interpolation

    인접한 64개의 pixel에 대해 Bilinear Interpolation과 같은 동작을 수행하여 계산

- size를 줄일때

  `cv2.INTER_AREA` : Area Interpolation

  pixel 영역 관계를 이용한 보간법

  

  



#### cv2.add

$$
dst(x, y) = saturate(src(x, y) + n)
$$

n만큼 밝아진 image가 출력된다.

**saturate** : n만큼의 수직 이동으로 인해 bottom 또는 top에 값이 완전히 밀착해버릴때 수행되는 연산을  saturate라고 한다.

![](https://blog.kakaocdn.net/dn/PvKl6/btqJDXzn63s/YdaJQTNQv8IerfwUjlDhA0/img.png)

```python
dst = cv2.add(src1, src2, dst = None, mask = None, dtype = None)
```

> `src1` : 첫 번째 입력 image
>
> `src1` : 두 번째 입력 image. 위 식에서 더해지는 n을 의미한다. 	
>
> 만약 n이 아닌, 다른 src를 입력하게 되면 말 그대로 두 image가 겹쳐진 모습으로 보여진다.
>
> `dst` : 출력 image
>
> `mask` : mask image
>
> `dtype` : dst의 type. 여기선 numpy의 dtype이 아닌, OpenCV의 dtype을 넣어줘야 하기 때문에 `cv2.CV_8U` 를 넣어줘야 한다.



**예시**

gray scale에선

```python
dst = cv2.add(src, 100)  # 100만큼 밝기 증가
```

> src는 ndarray이기 때문에 broadcasting을 이용하면 아래처럼 표현할 수 있다.
>
> ```python
> dst = src + 100
> ```
>
> 하지만 이는 saturate 연산이 이루어지지 않기 때문에 255보다 큰 값은 0으로 인식해버린다.

color scale에선 

```python
dst = cv2.add(src, (100, 100, 100, 0))  # 100만큼 밝기 증가
```



**그 외에도 다양한 밝기 조절 수식** 

###### cv2.addweighted

가중치 합
$$
dst(x, y) = saturate(\alpha * src1(x, y) + \beta * src2(x, y))
$$
보통 alpha + beta = 1 이 되도록 설정 (두 입력 image의 mean 밝기를 유지하기 위해)

```python
dst = cv2.addweighted(src1, alpha, src2, beta, gamma, dst = None, mask = None, dtype = None)
```

> `gamma` : dst에 추가적으로 더할 값 (+n)



**평균 연산**
$$
dst(x, y) = \frac{1}{2}(src1(x, y) + src2(x, y))
$$
alpha = beta = 0.5



###### cv2.subtract

뺄셈 연산
$$
dst(x, y) = saturate(src1(x, y) - src2(x, y))
$$





###### 

```python
dst = cv2.subtract(src1, src2, dst = None, mask = None, dtype = None)
```





###### cv2.absdiff

차이 연산

두 형상의 같은 위치에 존재하는 픽셀 값에 대해서 뺄셈 연산 후 절대값을 씌운다.

(틀린그림 찾기에서 틀린그림만 찾아내는데 사용될 수 있음)
$$
dst(x, y) = |src1(x, y) - src2(x, y)|
$$

```python
dst = cv2.absdiff(src1, src2, dst = None)
```





#### 논리 연산

두 연산의 각 pixel값을 이진수로 표현하고, 이에 대하여 비트 단위 AND, OR, XOR, NOT 연산을 수행

```python
dst = cv2.bitwise_and(src1, src2, dst = None, mask = None)
dst = cv2.bitwise_or(src1, src2, dst = None, mask = None)
dst = cv2.bitwise_xor(src1, src2, dst = None, mask = None)
dst = cv2.bitwise_not(src1, dst = None, mask = None)
```





### color

color image는 3 dim의 ndarray로 표현된다. `img.shape = (h, w, 3)`

OpenCV에서는 RGB순이 아닌, BGR순이다.

- 불러오기

  ```python
  img = cv2.imread('filename', cv2.IMREAD_COLOR)
  ```

- 생성

  ```python
  img = np.zeros((480, 640, 3), np.uint8)
  ```

- gary scale에서 color scale로 변경

  ```python
  img = cv2.cvtColor(img_gray, cv2.COLOR_GRAY2BGR)
  ```

  

#### cv2.split()

color image의 세 채널을 각각 분리하는 함수

```python
dst = cv2.split(img)
```

`img` : color image

`dst` : 각각의 원소에 B, G, R 의 값을 가진 list



#### cv2.merge()

여러 채널을 결합하는 함수 (흑백 3개를 하나의 color로)

```python
dst = cv2.merge(mv, dst = None)
```

`mv` : 입력 image list (개의 원소를 가진 1 dimension)



#### cv2.cvtColor()

color image를 다른 scale의 image로 변환

```python
dst = cv2.cvtColor(src, code, dst = None, dstCn = None)
```

`code` 변환하고자 하는 scale의 코드

![](https://github.com/HibernationNo1/TIL/blob/master/image/c7.jpg?raw=true)

> 그 외 코드는 [OpenCV 문서 페이지](https://docs.opencv.org/master/) 참고

`dstCn` : 결과 영상의 채널 수. 0 이면 자동 결정

- RGB색상을 gray scale로 변환

  장점: 데이터 저장 용량 감소, 데이터 처리 속도 향상

  단점: 색상 정보 손실



### Histogram

영상의 pixel 값 분포를 그래프의 형태로 표현한 것

ex) gray scale image에서 각 gray scale 값에 해당하는 pixel의 개수를 구하고, 이를 막대 그래프의 형태로 표현

![](https://opencv-python.readthedocs.io/en/latest/_images/image013.jpg)

이를 통해 image에서 어떤 밝기를 가진 pixel이 얼마나 존재하는지 유추할 수 있다.



#### cv2.calcHist()

히스토그램을 구할 수 있는 함수

```python
hist = cv2.calcHist(images, channels, mask, histSize, ranges, hist = None, accumulate = None)
```

`hist` : 계산된 histogram (ndarray)

`images` : 입력 image list

`channels` : histogram을 구할 채널을 나타내는 list

> gray scale의 hist를 구하려면 [0]
>
> BGR 의 hist를 구하려면 [0, 1, 2]

`mask` : mask image. 입력 image 전체에서 histogram을 구하려면 None 지정

`histSize` : histogram 각 dimension의 크기(bin의 개수)를 나타내는 list

> gray scale은 [256]

`range` : histogram 각 dimension의 min과 max로 구성된 list

> gray scale은 [0, 256]

`accumulate`  : 기존의 hist에 누적하려면 True, 새로 만드려면 False



**예시**

- gray scale image

```python
src = cv2.imread('lenna.bmp', cv2.IMREAD_GRAYSCALE)

if scr is None:
    print('Image load failed')
    sys.exit()
    
hist = cv2.calcHist([src], [0], None, [256], [0, 256])
# src을 입력. gray scale이기 때문에 2번째 인자 [0], mask 없음, histSize와 min, max 는 gray scale이기 때문에 [256], [0, 256]

cv2.imshow()
cv2.waitKey(1)  

plt.plot(hist)  # histogram을 보려면 matlplotlib 사용
plt.show()
```



- color image

```python
src = cv2.imread('lenna.bmp')

if scr is None:
    print('Image load failed')
    sys.exit()
    
colors = ['b', 'g', 'r']
bgr_planes = cv2.split(src)  # color를 각 scale로 분리, list로 저장

for (p, c) in zip(bpr_planse, colors):
    hist = cv2.calcHist([p], [0], None, [256], [0, 256])
    plt.plot(hist, color = c)
    # 각 scale마다 for문으로 입력, 각 scale은 color에서 split되었기 때문에 gray 		scale이므로 [0], [256], [0, 256]
	
cv2.imshow()
cv2.waitKey(1)  

plt.plot(hist)  # histogram을 보려면 matlplotlib 사용
plt.show()
```



#### cv2.nomalize()

image의 histogram이 전 구간에 걸쳐 나타나도록 변경하는 선형 변환 기법

**히스토그램 스트레칭** 이라고 한다.

이는 OpenCV에서 지원하는 정규화 함수를 사용해서 구현할 수 있다.

```python
dst = cv2.normalize(src, dst, alpha = None, beta = None, norm_type=None, dtype = None, mask = None)
```

`alpha` : nomalize 구간 min (0)

`beta` : nomalize 구간 max (255)

`norm_type` : 정규화 type

> 보통 NORM_MINMAX 사용

`src` : image 또는 histogram

> histogram을 인자로 준다면 너무 큰 값이 있을 때 작은 값들이 없는 것 처럼 여겨지기 때문에 
>
> log scale로 인자를 줘야 한다. 또한 hist에 0인 원소가 있을 것도 대비해서 +1을 해준다.
>
> `cv2.log(hist + 1)`



#### Histogram equalization

**히스토그램 평활화** 라고 한다.

Histogram이 gary scale 전체 구간에서 균일한 분포로 나타나도록 변경하는 명암비 향상 기법

수식
$$
Histogram\ function:\ h(g) = N_g \\
nomalized\ Histogram\ function: \ p(g) = \frac{h(g)}{w*h}\\
누적\ 분포\ 함수(cdf) : \ cdf(g) = \sum_{0 =< j<g} p(i)
$$
변환 함수 
$$
dst(x, y) = round(cdf(src(x, y))*L_{max})
$$


```python
dst = cv2.equalizeHist(src, dst = None)
```

`src` : gray scale image만 가능



- 히스토그램 스트레칭과의 차이점

  ![](https://github.com/HibernationNo1/TIL/blob/master/image/c8.jpg?raw=true)

- color image에 적용할 때

  ![](https://github.com/HibernationNo1/TIL/blob/master/image/c9.jpg?raw=true)



### Contrast(명암비)

Contrast : 대비
$$
dst(x,y) = saturate(src(x, y) + (src(x, y)-128)*\alpha)
$$
OpenCV에서는 이 동작을 지원해주는 함수가 없기 때문에 numpy로 계산해야 한다.



### 특정 Color 영역 추출

#### cv2.inRange

일반적으로, 특정  Color 영역을 추출하는 방법은 RGB 색 공간에서 추출하는 것 보다, HSV색 공간에서 추출하는 것을 더 선호한다. (밝기 성분 때문에)

![](https://github.com/HibernationNo1/TIL/blob/master/image/c10.jpg?raw=true)

H : 각도 (0~180도, 반 시계방향)

S : 색의 선명도. 원의 반지름 상의 특정 영역

V : 밝기 성분. 0이 어둡, 255이 밝음.  (위 이미지는 밝은 녹색~어두운 녹색 전부 추출)



```python
dst = cv2.inRange(src, lowerb, upperb, dst = None)
```

`lowerb` : 하한 값 matrix(ndarray) 또는 scalar  (BGR or RGB or HSV)

`upperb`: 상한 값 matrix(ndarray) 또는 scalar

`dst` : mask image 형태로 0 또는 1의 값을 가진 이진 image를 반환한다.



**예시**

```python
src = cv2.imread('candies.png')

if src is None: 
    print('Image load failed!')
    sys.exit()
    
src_hsv = cv2.cvtColor(src, cv2.COLOR_BGR2HSV) # BGR색 채널을 HSV 색 채널로 변경

dst1 = cv2.inRange(src, (0, 128, 0), (100, 255, 100)) # BGR색 공간에서 초록색 영역 추출
dst2 = cv2.imRange(src_hsv, (50, 150, 0), (80, 255,255)) # HSV색 공간에서 초록색 영역 추출

cv2.imshow('src', src)
cv2.imshow('dst1', dst1)
cv2.imshow('dst2', dst2)
cv2.waitKey()
```



#### Histogram Backprojection

히스토그램 역투영

image의 각 pixel이 주어진 histogram model에 얼마나 일치하는지를 검사하는 방법으로, 임의의 색상 영역을 검출할 때 효과적이다.

Histogram Backprojection은 미리 계산된 Histogram을 사용해서 Histogram 정보와 부합하는 영역을 찾아 동작하게 된다.

정리하자면, 특정 영역의 color를 histogram으로 계산을 한 후, 해당 histogram을 사용해서 역투영을 하는 것이다.

```python
dst = cv2.calcBackProject(src, channels, hist, ranges, scale)
```

`src` : 입력 image list

`channels` : 역투영 계산에 사용할 채널 번호 list

`hist` : 입력 Histogram

> calcHist()를 통해 Histogram을 구할 때, photoshop과 같은 툴을 사용해서 mask image를 따놓아야 해당 영역에 대한 통일된 color를 찾는데 더욱 편리하다.

`ranges` : Histogram 각 dimension의 최솟값과 최대값으로 구성된 list

`scale` : 출력 역투형 matrix에 추가적으로 곱할 값



## 크로마 키 합성 

Chroma Key 합성: 녹색 또는 파란색 배경에서 촬영한 영상에 다른 배경 영상을 합성하는 기술

**순서**

1. 녹색 스크린 영역 추출하기

2. 녹색 영역에 다른 배경 영상을 합성하여 저장하기



#### 녹색 스크린 영역 추출하기

1. 크로마 키 image를 HSV color space로 변환

2. cv2.inRange() 함수를 사용해서 특정 범위 영역을 검출
   $$
   50 \leq H \leq80, \ 150 \leq S \leq 255,\ 0 \leq V \leq 255
   $$

   > 초록색 영역



#### 녹색 영역에 다른 image 합성

1. mask 연산을 지원하는 cv2.copyTo() 함수 사용



#### code.py

```python
import sys
import numpy as np
import cv2


# 내 카메라
cap1 = cv2.VideoCapture(0)

if not cap1.isOpened():
    print('video open failed!')
    sys.exit()

# 비오는 배경 동영상
cap2 = cv2.VideoCapture('raining.mp4')

if not cap2.isOpened():
    print('video open failed!')
    sys.exit()


w = round(cap1.get(cv2.CAP_PROP_FRAME_WIDTH)) 
h = round(cap1.get(cv2.CAP_PROP_FRAME_HEIGHT)) 
frame_cnt1 = round(cap1.get(cv2.CAP_PROP_FRAME_COUNT))
frame_cnt2 = round(cap2.get(cv2.CAP_PROP_FRAME_COUNT))
print(f'w x h : {w} x {h}')
print('frame_cnt1:', frame_cnt1)
print('frame_cnt2:', frame_cnt2)

# video의 frame/ms 계산
fps = cap1.get(cv2.CAP_PROP_FPS)  # cap1의 초당 프레임 수 반환
delay = int(1000 / fps)

# 출력 동영상 객체 생성
fourcc = cv2.VideoWriter_fourcc(*'DIVX')
out = cv2.VideoWriter('output.avi', fourcc, fps, (w, h))

# 합성 여부 플래그
do_composit = False  #True면 합성

# 전체 동영상 재생
while True:
    ret1, frame1 = cap1.read() #

    if not ret1:
        break
    
    # do_composit 플래그가 True일 때에만 합성
    if do_composit:
        ret2, frame2 = cap2.read()

        if not ret2:
            break

        frame2 = cv2.resize(frame2, (w, h))

        # HSV 색 공간에서 녹색 영역을 검출하여 합성
        hsv = cv2.cvtColor(frame1, cv2.COLOR_BGR2HSV)
        mask = cv2.inRange(hsv, (50, 150, 0), (70, 255, 255))
        cv2.copyTo(frame2, mask, frame1)

    cv2.imshow('frame', frame1)
    key = cv2.waitKey(delay)

    # 스페이스바를 누르면 do_composit 플래그를 변경
    if key == ord(' '):
        do_composit = not do_composit
    elif key == 27:
        break

cap1.release()
cap2.release()
cv2.destroyAllWindows()
```



연습

```python
# 내 camera open   또는 `woman.mp4`
 
# 배경 동영상 open  'raining.mp4'

# 내 camera의 pixel size구하기

# 두 video의 frame 수 구하기

# 내 camera의 fps 구하고 deley 계산

# 동영상 저장 'output.avi'

# 동영상 재생

        # Video2의 크기를 camera 화소에 맞게 재설정

        # HSV 색 공간에서 녹색 영역 검출
        # (50, 150, 0), (70, 255, 255)

    # 스페이스바 누르면 플래그 변경

# 자원 삭제
```

